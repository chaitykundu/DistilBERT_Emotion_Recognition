{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5rzjoZ6VB5W+FF8Jm9P4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitykundu/DistilBERT_Emotion_Recognition/blob/main/SpeechToText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# Ensure GEMINI_API_KEY is available from a previous cell execution (e.g., cell c49d2863)\n",
        "# The client must be initialized after the GEMINI_API_KEY variable is defined.\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "\n",
        "def moderate_image(image_path):\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=[\n",
        "            types.Part.from_image(image_path),\n",
        "            \"Is this image safe for a social chat app? Answer only 'safe' or 'unsafe' with reason.\"\n",
        "        ]\n",
        "    )\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "AQa3NzPXFPVg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8859e529"
      },
      "source": [
        "### Set your Gemini API Key in Colab\n",
        "\n",
        "For secure handling of your API key in Colab, it's recommended to use the **Colab secrets manager**.\n",
        "\n",
        "1.  Click the \"ðŸ”‘\" icon in the left-hand panel.\n",
        "2.  Click \"Add a new secret\".\n",
        "3.  For the **Name**, use `GEMINI_API_KEY` (or any name you prefer, just ensure it matches the code).\n",
        "4.  For the **Value**, paste your actual Gemini API key.\n",
        "5.  Ensure \"Notebook access\" is toggled on.\n",
        "\n",
        "Once set, you can access it in your code like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c49d2863",
        "outputId": "8ec4cd26-fc97-408e-d6b9-f6a316dd20bc"
      },
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Configure the genai library with your API key\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "print(\"API key configured successfully!\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myfile = client.files.upload(file=\"/content/Small Talk  Everyday English.mp3\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\", contents=[\"Describe this audio clip\", myfile]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv1rSsy69u5D",
        "outputId": "4349986c-b884-47df-89aa-0f11358976d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The audio clip features a conversation between two male speakers, interspersed with distinct sound effects.\n",
            "\n",
            "It begins with a retro video game-like rhythmic sound, composed of light, percussive elements, reminiscent of blocks being placed or a chiptune melody. This is followed by a brief silence, then a series of quick, sharp clicking or tapping sounds, like wood blocks.\n",
            "\n",
            "Two male voices then engage in a conversation. The first speaker asks about the second speaker's new job. The second speaker describes his positive experience, praising his friendly co-workers, a flexible and fun atmosphere, and a hilarious boss. He highlights the lack of a strict dress code and the ability to set his own hours (coming in when he wants, leaving early if he starts early).\n",
            "\n",
            "The conversation then shifts to their preferred working hours. The second speaker expresses a strong preference for finishing early and enjoying the morning, mentioning running and watching the sunrise while drinking coffee. The first speaker, however, states he is the \"opposite\" â€“ a \"night owl\" who enjoys sleeping in and is most alert in the evenings. During this remark, the distinct sound of an **owl hooting** is heard. The second speaker concludes with the proverb, \"the early bird catches the worm,\" prompting the first speaker to consider trying to go to bed earlier.\n",
            "\n",
            "The clip ends with the return of the same retro video game-like rhythmic sound and percussive taps as heard at the beginning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e16b3d1a"
      },
      "source": [
        "Alternatively, if you prefer not to use the secrets manager (though not recommended for sharing notebooks or sensitive keys), you can directly assign the key (replace `\"YOUR_ACTUAL_API_KEY\"` with your key):\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.count_tokens(\n",
        "  model='gemini-2.5-flash', # Add the missing 'model' argument\n",
        "  contents=[myfile]\n",
        ")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eVyoVBNpiAF",
        "outputId": "927e261b-2c71-425a-b4fc-a748912f0d1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sdk_http_response=HttpResponse(\n",
            "  headers=<dict len=10>\n",
            ") total_tokens=4266 cached_content_token_count=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T040b7Wz-QOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or9-TMQK-QIy",
        "outputId": "db5def9a-d4fc-49bf-c238-4e8c741f3d19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")  # Options: tiny, base, small, medium, large\n",
        "result = model.transcribe(\"/content/Small Talk  Everyday English.mp3\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxQRf7nm-QFq",
        "outputId": "866478e0-b621-4d93-d43a-bc7683bb1601"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " So, what's new Mark? How is your new job going? To be honest, I can't complain. I really love the company that I am working for. My co-workers are all really friendly and helpful. They really help me feel welcome. It's a really energetic and fun atmosphere. My boss is hilarious and he's really flexible. Really? How so? He allows me to come in when I want and make my own hours. I can also leave early if I start early. There is no real dress code either. I can wear jeans and a t-shirt if I want. I can even wear shorts in the summer. Wow. It sounds really cool. I can't stand wearing a suit every day. Which do you prefer? Working late or finishing early? I prefer finishing early. I really enjoy the morning. I love getting up early and going for a run. There is nothing like watching the sunrise while drinking my morning coffee. Really? I am opposite. I love sleeping in. I am most alert in the evenings. I'm a real night owl. Well, you know what they say. The early bird catches the worm. You know, you could be right. Maybe I will try to go to bed a little earlier tonight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")  # Options: tiny, base, small, medium, large\n",
        "result = model.transcribe(\"/content/Best FREE Speech to Text AI - Whisper AI.mp4\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjZaa5aRArw4",
        "outputId": "85d42451-1f57-4e06-e2ed-93d8821135e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hi everyone, Kevin here. Today we're going to look at how you can take speech and turn it into text using AI. And the really crazy thing is that it does a better job than most humans. You can use it with English and 96 other languages. It works even if you have a lot of background noise. And it's also the stuff if you have a very sick accent. The best part is that it's completely free and also open source. Let's check out how to do this. We're going to use an AI tool called Whisper. Whisper is made by a company called OpenAI. And you might have heard of them before. That's the same company behind the immensely popular chat GPT, which allows you to converse with a computer. There are also the company behind Dolly too, where you can type in some text, and then it'll generate an image based on that text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")  # Options: tiny, base, small, medium, large\n",
        "# Corrected: Using an audio file instead of an image file\n",
        "result = model.transcribe(\"/content/English conversation ( Planning of a friend's wedding) @AleenaRaisLive @english.tangerineacademy [VcopxlQmDEk].mp3\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GpABOvzBKx7",
        "outputId": "c47c1ad5-3089-486c-8a61-7d1a13d69470"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hey! I heard that you're planning your friend's wedding party. How it going so far? It's quite exciting but also a bit overwhelming. There are so many things to consider and organize. I can imagine. Where are you thinking of hosting the party? They have decided to have it in a beautiful garden venue. Near their hometown. It's a lovely outdoor setting perfect for a romantic wedding. That sounds wonderful. You started working on the guest list. Yes. We have started compiling a list based on their preferences and budget. It is a tough task. You know. I understand. What about the wedding planner? Since the couple has a tight budget, they have decided to plan everything themselves. That's impressive. It will definitely save them some money. What about the decorations and theme? They are leaning towards a rustic theme with lots of greenery and natural elements. That sounds lovely and will create a cozy atmosphere. What about the menu? Have you discussed it with the couple? They want to have a diverse menu that caters to different dietary preferences. We are currently exploring different catering options. And doing tastings to ensure everything is delicious. Also, we are thinking of having a live band for reception. To make wedding party even more memorable and enjoyable. That's a fantastic idea. Do you need my assistance with anything? Thank you for offering. We might need some help with crafting the wedding invitations. I will let you know when we reach that stage. Consider it done. I will be there to listen and support you throughout the entire process. Thank you so much. Your support means a lot to me and the couple. I am confident that it's going to be a beautiful AMD memorable celebration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7am7voFbBaa7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}